{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26972de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Texto generado:\n",
      " En el vasto lienzo de la noche, la luna asoma,  \n",
      "un faro de plata que susurra secretos antiguos.  \n",
      "Sus rayos acarician la piel del mundo dormido,  \n",
      "tejiendo sombras danzantes entre susurros de viento,  \n",
      "mientras el tiempo se detiene, atrapado en su abrazo.\n",
      "\n",
      "Texto refinado:\n",
      " En el vasto lienzo de la noche, la luna se asoma,  \n",
      "un faro de plata que susurra secretos antiguos.  \n",
      "Sus rayos acarician la piel del mundo dormido,  \n",
      "tejiendo sombras danzantes entre los susurros del viento,  \n",
      "mientras el tiempo se detiene, cautivo en su abrazo.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "# Configurar el modelo OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Paso 1 - Prompt de generación con Chain of Thought\n",
    "system_template = \"Eres un escritor creativo que razona paso a paso.\"\n",
    "human_template = (\n",
    "    \"Piensa en pasos lógicos y escribe un texto de 5 líneas \"\n",
    "    \"sobre '{topic}' en estilo {style}.\"\n",
    ")\n",
    "\n",
    "system_msg_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_msg_prompt, human_msg_prompt])\n",
    "\n",
    "generate_chain = LLMChain(llm=llm, prompt=chat_prompt, output_key=\"generated_text\")\n",
    "\n",
    "# Paso 2 - Refinar el texto generado\n",
    "refine_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"Ahora eres un editor que pule textos.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Pulir el siguiente texto para mejorar claridad y estilo:\\n\\n{generated_text}\"\n",
    "    )\n",
    "])\n",
    "refine_chain = LLMChain(llm=llm, prompt=refine_prompt, output_key=\"refined_text\")\n",
    "\n",
    "# Cadena secuencial\n",
    "chain = SequentialChain(\n",
    "    chains=[generate_chain, refine_chain],\n",
    "    input_variables=[\"topic\", \"style\"],\n",
    "    output_variables=[\"generated_text\", \"refined_text\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Ejecutar el chain\n",
    "outputs = chain({\"topic\": \"la luna\", \"style\": \"poético y evocativo\"})\n",
    "print(\"Texto generado:\\n\", outputs[\"generated_text\"])\n",
    "print(\"\\nTexto refinado:\\n\", outputs[\"refined_text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
