{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e3686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for diagnostic messages is a test\n",
      "\n",
      "\n",
      "The diagnostic message for this input would likely be something along the lines of: \"Diagnostic results: No issues found in the input provided.\"\n",
      "\n",
      "Analysis: \n",
      "\n",
      "The mood of this story is gloomy and pessimistic. The description of the day as dark and the use of words like \"dreading,\" \"irritable,\" and \"annoyance\" all contribute to a negative and unhappy mood. The constant rain and thunder add to the sense of dreariness and the feeling that everything is going wrong. Overall, the mood is one of sadness, frustration, and a general sense of negativity.\n",
      "dict_keys(['topic', 'story', 'analysis'])\n",
      "dict_keys(['story', 'topic', 'analysis'])\n",
      "dict_keys(['analysis'])\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "# Initialize the model\n",
    "# llm = GoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "result = llm.invoke(\"Test input\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "# First chain generates a story\n",
    "story_prompt = PromptTemplate.from_template(\n",
    "    \"Write a short -5 lines - story about {topic} in a bad mood.\"\n",
    ")\n",
    "story_chain = story_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Second chain analyzes the story\n",
    "analysis_prompt = PromptTemplate.from_template(\n",
    "    \"Analyze the following story's mood:\\n{story}\"\n",
    ")\n",
    "analysis_chain = analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Combine chains\n",
    "story_with_analysis = story_chain | analysis_chain\n",
    "\n",
    "# Run the combined chain\n",
    "story_analysis = story_with_analysis.invoke({\"topic\": \"a rainy day\"})\n",
    "print(\"\\nAnalysis:\", story_analysis)\n",
    "\n",
    "# Using RunnablePassthrough.assign to preserve original data\n",
    "enhanced_chain = RunnablePassthrough.assign(\n",
    "    story=story_chain  # Add 'story' key with generated content\n",
    ").assign(\n",
    "    analysis=analysis_chain  # Add 'analysis' key with analysis of the story\n",
    ")\n",
    "\n",
    "# Execute the chain\n",
    "result = enhanced_chain.invoke({\"topic\": \"a rainy day\"})\n",
    "print(\n",
    "    result.keys()\n",
    ")  # Output: dict_keys(['topic', 'story', 'analysis']) # dict_keys(['topic', 'story', 'analysis'])\n",
    "# For more control over the output structure, we could also construct dictionaries manually:\n",
    "\n",
    "# Alternative approach using dictionary construction\n",
    "manual_chain = (\n",
    "    RunnablePassthrough()  # Pass through input\n",
    "    | {\n",
    "        \"story\": story_chain,  # Add story result\n",
    "        \"topic\": itemgetter(\"topic\"),  # Preserve original topic\n",
    "    }\n",
    "    | RunnablePassthrough().assign(  # Add analysis based on story\n",
    "        analysis=analysis_chain\n",
    "    )\n",
    ")\n",
    "result = manual_chain.invoke({\"topic\": \"a rainy day\"})\n",
    "print(result.keys())  # Output: dict_keys(['story', 'topic', 'analysis'])\n",
    "\n",
    "# We can simplify this with dictionary conversion using a LCEL shorthand:\n",
    "# Simplified dictionary construction\n",
    "simple_dict_chain = story_chain | {\"analysis\": analysis_chain}\n",
    "result = simple_dict_chain.invoke({\"topic\": \"a rainy day\"})\n",
    "print(result.keys())  # Output: dict_keys(['analysis', 'output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
